\section{Support Vector Machine}
\label{mainsec:svm}
\textit{Manuel Dudda, Benjamin Weißer}

Im Jahr 1958 veröffentlichte der Psycholge und Informatiker Frank Rosenblatt sein entwickeltes Konzept des Perzeptrons \cite{rosenblatt58a}. 
Die Idee entstammt der Neurobiologie und simuliert die Funktionsweise eines menschlichen Gehirns. 
Perzeptronen sind vereinfachte künstliche neuronale Netze, bestehend aus mehreren künstlichen Neuronen, die ein formales Modell einer Nervenzelle beschreiben. 
In der Grundversion besteht ein Perzeptron aus einem einzigen Neuron. 
Es verarbeitet einen Eingabevektor zu einer Ausgabe. 
Anhand eines Schwellwertes wird entschieden, ob das Neuron "{}feuert"{} oder nicht. 
Bei der Verarbeitung des Eingabevektors wird für jede Komponente eine Gewichtung berücksichtigt, sodass die Ausgabe auf gewisse Eingaben eingestellt werden kann. 
Mehrlagige Perzeptronen (\ac{MLP}) sind in der Lage, Eingabevektoren in Ausgabevektoren umzuwandeln. 

\begin{figure}[htbp] \centering
    \subfigure[AND-Pezeptron mit einem Neuron]{\includegraphics[width=0.23\textwidth]{svm/svm_perceptron.png}}
    \subfigure[AND linear separierbar in $\mathbb{R}^2$]{\includegraphics[width=0.23\textwidth]{svm/svm_and.png}}
    \caption{AND-Perzeptron}
    \label{fig:perceptron_and}
\end{figure}

Die jeweiligen Gewichtungen können so eingestellt werden, dass der Eingabevektor in einen bestimmten Ausgabevektor umgewandelt wird. 
Abb. \ref{fig:perceptron_and} zeigt, wie ein einfaches Perzeptron die AND-Funktion realisiert, und visualisiert die Klassifizierungsentscheidung in einem Koordinatensystem. 

Einlagige Perzeptronen sind beschränkt auf die Lösung linear separierbarer Probleme. 
Ein einfaches XOR kann also nicht realisiert werden (Abb. \ref{fig:perceptron_xor}). 

\begin{figure}[htbp] \centering
    \includegraphics[width=0.23\textwidth]{svm/svm_xor.png}
    \caption{XOR nichtlinear separierbar in $\mathbb{R}^2$}
    \label{fig:perceptron_xor}
\end{figure}


Mit einem Trick, der Erhöhung der Dimension, können mehrlagige Perzeptronen auch nichtlinear separierbare Probleme lösen. 
So lässt sich bspw. das XOR-Problem in einem 3-dimensionalen Raum durch eine Hyperebene trennen (\ref{fig:perceptron_xor3d}).

\begin{figure}[htbp] \centering
    \includegraphics[width=0.23\textwidth]{svm/svm_xor_3d.png}
    \caption{XOR linear separierbar in $\mathbb{R}^3$}
    \label{fig:perceptron_xor3d}
\end{figure}

Die Wahl der richtigen Gewichte ist dabei nicht einfach, für komplexere Problemstellungen schier unmöglich. 
Um dennoch eine Problemlösung zu modellieren, die Eingaben richtig klassifiziert, gibt es einen Algorithmus, der die Gewichte automatisch anpasst.
Dieser Algorithmus setzt eine Trainingsmenge voraus, für dessen Eingabevektoren die zugehörigen Klassen bekannt sind. 
Durch Fehlerrückführung kann ein \ac{MLP} trainiert werden und das Netz kann die gewünschten Muster nach einer kontrollierten Trainingsphase klassifizieren.

Knapp 40 Jahre Jahre später veröffentlichte der sowjetisch-amerikanische Mathematiker Wladimir Wapnik \cite{Vapnik} das Prinzip der Support-Vector-Machines (\ac{SVM}).

Im Gegensatz zu \ac{MLP}s wird die Anpassung der Trennung nicht empirisch durch Trainingsmethoden, sondern durch die Datengrundlage mathematisch optimal ermittelt. 
SVMs können auch nichtlinear separierbare Probleme lösen, ohne die Dimension der Eingabe zu erhöhen. 
Die Hauptidee dabei ist die Repräsentation der Daten zu verändern. 
Mit Hilfe des sogenannten Kernel-Tricks werden die Daten in einen höherdimensionalen Raum transformiert. 

Support Vector Machines erfreuen sich großer Beliebtheit, da sie in der Regel wesentlich performanter vernünftige Vorhersagen treffen können. Lediglich durch die Lokalisierung des Objekts im Koordinatensystem wird klassifiziert. Dadurch, dass eine trainierte SVM eine Trenngerade generiert, kann durch einfache Hilfsmittel aus der linearen Algebra die relative Position bestimmt werden. Es wird also entschieden, ob das zu klassifizierende Objekt "{}oberhalb"{} oder "{}unterhalb"{} der Trenngeraden liegt. Allerdings ist zu beachten, dass für sehr große Datenmengen die \ac{SVM} eine sehr lange Trainingsphase benötigt, da der Algorithmus die Inversion der Eingabematrix benutzt. Das Bilden der inversen Matrix hat eine Laufzeit zwischen $\mathcal O(n^2)$ und $\mathcal O(n^3)$ und ist damit sehr aufwändig.

\subsection{Funktionsweise der SVM}

\subsubsection{Optimale Trennung}
Mit einem Satz von Merkmalsvektoren (Merkmalsraum) und dessen Klassenzugehörigkeiten $\{ (x_1, y_1), ..., (x_m, y_m) | x_i \in \mathcal{X}, y_i \in \{-1, 1\}, m \in \mathbb{N} \}$ wird eine mathematische Gerade errechnet,
die in einem Koordinatensystem betrachtet die Daten räumlich in zwei Klassen trennt. 

Die Gerade (Hyperebene im mehrdimensionalen Raum) trennt die Merkmalsräume bestmöglich und dient als Entscheidungsfunktion für die Klassifikation. Sie ist gegeben durch den Normalenvektor $w$ und den sogenannten Bias $b$, dem Abstand der Ebene zum Ursprung. Diese Form erweist sich als besonders praktisch, da durch Einsetzen von $x$ der direkte Abstand zur Hyperbene resultiert.
Intuitiv ist klar, dass alle Punkte auf der Hyperebene selbst keinen Abstand haben, die Formel der Hyperebene (\ref{eq:svm_hyperplane}) lautet demnach: 
 
\begin{equation}
\label{eq:svm_hyperplane}
    \mathcal{H}: \{ x \,|\, \langle w,x \rangle + b = 0 \}
\end{equation}
 
Allein durch das Vorzeichen der Entscheidungsfunktion ordnet die \ac{SVM} die Eingabe einr Klasse zu. Dabei können nur zwei Klassen  prognostiziert werden. Die Klasse gehört demnach entweder zur Klassenmenge \ref{eq:svm_decision0} oder zu \ref{eq:svm_decision1}.

\begin{eqnarray}
    \mathcal{C}_{-1}: \{ c \,|\, \operatorname{sgn}(\langle w,x \rangle + b) = -1 \} \label{eq:svm_decision0} \\
    \mathcal{C}_1: \{ c \,|\, \operatorname{sgn}(\langle w,x \rangle + b) = 1 \} \label{eq:svm_decision1}
\end{eqnarray}

Die nächstliegenden Vektoren zur Trenngeraden werden als Stützvektoren, der Abstand als Margin $M$ bezeichnet (Abb. \ref{fig:svm_separator}). 

\begin{figure}[htbp] \centering
    \includegraphics[width=0.38\textwidth]{svm/svm_overview.png}
    \caption{Trenngerade einer SVM}
    \label{fig:svm_separator}
\end{figure}

Die Stützvektoren bilden das tragende Konstrukt der Entscheidungsfunktion. 
Alle andere Merkmalsvektoren haben keinen Einfluss auf die Trennung, was die Namensgebung der Stützvektoren begründet. 
Das macht die \ac{SVM} zu einem sehr transparenten und performanten Klassifikator. 

\subsubsection{Kernel-Trick}
Es ergeben sich Unregelmäßigkeiten bei der Lösung von nichtlinear separierbaren Problemen und der Klassifikation von mehr als 2 Klassen.
Im Gegensatz zu den MLPs umgeht man diesen Umstand nicht mit der Erhöhung der Dimension. 
Die \ac{SVM}s setzen in diesem Falle auf die Transformation der Datenrepräsentation. 
Mit Hilfe von Kernfunktionen (\ref{eq:svm_kernel_function}) lassen sich Daten von $\mathbb{R}^n$ in einen höherdimensionalen Raum $\mathbb{R}^h$ transformieren, in dem sie linear separierbar erscheinen (Abb. \ref{fig:svm_kernel}). 

\begin{equation}
\label{eq:svm_kernel_function}
\begin{split}
    \phi : & \mathbb{R}^n \to \mathbb{R}^h \\
    & x \mapsto \phi(x)
\end{split} 
\end{equation}

\begin{figure}[htbp] \centering
    \subfigure[$x$ nichtlinear separierbar in $\mathbb{R}^n$]{\includegraphics[width=0.23\textwidth]{svm/svm_fitting-line.png}}
    \subfigure[$\phi(x)$ linear separierbar in $\mathbb{R}^h, h>n$]{\includegraphics[width=0.23\textwidth]{svm/svm_linear-fitting.png}}
    \caption{Kernfunktion $\phi$}
    \label{fig:svm_kernel}
\end{figure}

Als Bedingung des Raums $\mathbb{R}^h$ gilt, dass das Skalarprodukt erklärt ist. 
Wir haben nach der Transformation also die neue Form (\ref{eq:svm_kern_tranformation}). 
In der müssen wir nun das Skalarprodukt $\langle\phi(w),\phi(x)\rangle$ ausrechnen, was sehr schwierig (bzw. unmöglich) ist, wenn die Dimension von $\mathbb{R}^h$ zu groß wird.

\begin{equation}
\label{eq:svm_kern_tranformation}
    \mathcal{C}: \{ c_i \,|\, \operatorname{sgn}(\langle \phi(w),\phi(x) \rangle + b) = i \}
\end{equation}

Dadurch, dass die Trainingspunkte $x$ nur in Skalarprodukten auftauchen, können wir uns des Kernel-Tricks bedienen.
Kernfunktionen, die in $\mathbb{R}^n$ leben, zeichnen sich durch eine spezielle Eigenschaft aus, da sie sich verhalten wie ein Skalarprodukt in $\mathbb{R}^h$ (\ref{eq:svm_kern_trick}). 

\begin{equation}
\label{eq:svm_kern_trick}
    \mathcal{K}(w,x) = \langle\phi(w),\phi(x)\rangle
\end{equation}

Es kann also das Skalarprodukt $\langle\phi(w),\phi(x)\rangle$ in $\mathbb{R}^h$ ausgerechnet werden, ohne die Daten mittles $\phi$ zu transformieren. 
Das Beispiel \ref{fig:ex_kernel} verdeutlicht die Anwendung des Kernel-Tricks  anhand einer polynomiellen Kernfunktion.

\renewcommand{\figurename}{Bsp.}
\begin{figure}[htbp]
\begin{equation*}
\label{eq:svm_kernel_example}
\begin{split}
    \text{Seien } w,x & \in \mathbb{R}^2 \text{ und}\\
    \phi : & \mathbb{R}^2 \to \mathbb{R}^3\\
    & \begin{pmatrix}
    x_1 \\
    x_2
    \end{pmatrix}
    \mapsto
    \begin{pmatrix}
    x_1^2 \\
    \sqrt{x_1x_2} \\
    x_2^2
    \end{pmatrix}\\
    \text{dann ist:} &\\
    \langle \phi(w),\phi(x) \rangle = & \:\langle \begin{pmatrix}
    w_1^2 \\
    \sqrt{w_1w_2} \\
    w_2^2
    \end{pmatrix},
    \begin{pmatrix}
    x_1^2 \\
    \sqrt{x_1x_2} \\
    x_2^2
    \end{pmatrix} \rangle \\
    \\
    = & \:w_1^2x_1^2 + 2 w_1x_1w_2x_2 + w_2^2x_2^2 \\
    = & \:(w_1x_1 + w_2x_2)^2 \\
    = & \:\langle w,x \rangle^2 \overset{\text{(def)}}= \mathcal{K}(w,x)
\end{split}
\end{equation*}
    \caption{Beispiel einer polynomiellen Kernfunktion}
    \label{fig:ex_kernel}
\end{figure}

\newpage

Nicht jede beliebige Funktion ist eine Kernfunktion. Kernfunktionen müssen die Bedingungen nach dem Satz von Mercer \cite[S. 127]{Marsland} erfüllen. 
Gängige Kernfunktionen sind:
\begin{itemize}
\item{linear: $\mathcal{K}(w,x) = \langle w,x \rangle$}
\item{polynomiell: $\mathcal{K}(w,x) = (\gamma\langle w,x \rangle+c_0)^d$}
\item{sigmoid: $\mathcal{K}(w,x) = \tanh(\gamma\langle w,x \rangle+c_0)$}
\item{rbf: $\mathcal{K}(w,x) = \exp(- \gamma \|w - x \| ^2)$}
\end{itemize}

\subsubsection{Klassifikation von mehreren Klassen}
Da die \ac{SVM} als binärer Klassifikator entwickelt wurde, müssen für eine Klassifikation von mehr als zwei Klassen Strategien entwickelt werden, um das Prinzip der \ac{SVM} zu erweitern. 
Ein Verfahren ist die \textit{Einer gegen den Rest}-Klassifikation. 
Bei dieser Technik wird für jedes zu klassifizierende Objekt eine binäre \ac{SVM}-Instanz trainiert. 
Für jede \ac{SVM} wird eine Klasse separiert, die anderen Klassen werden nicht unterschieden und als negative Beispiele zu einer Restklasse definiert. 
Die Vorraussage eines Objektes ergibt sich aus der Auswertung aller \ac{SVM}-Instanzen. 
Es ist nun möglich, dass mehrere Instanzen eine positive Klassenzuordnung feststellen und nicht die Restklasse klassifizieren. 
In diesem Fall entscheidet sich das \textit{Einer gegen den Rest}-Verfahren für die Klasse, dessen \ac{SVM} die höchste Ausgabe erzeugt (\textit{winner-takes-all}). 
Als höchstes Ergebnis wird der größte Abstand zur Trennhyperebene angenommen. 
Offensichtlich erhöht sich die Laufzeit der Trainingsphase mit der Anzahl der Klassen $|\mathcal{C}|$. 
Glücklicherweise beeinflusst das nicht die Laufzeitanalyse in der $\mathcal{O}$-Notation (\ref{eq:svm_winner_runtime}). 

\begin{equation}
\label{eq:svm_winner_runtime}
    \underbrace{\mathcal{O}(n) + ... + \mathcal{O}(n)}_{|\mathcal{C}|-mal} = |\mathcal{C}| \cdot \mathcal{O}(n) = \mathcal{O}(n)
\end{equation}

Sind die SVMs trainiert, beeindrucken sie durch rasante Klassifikation. 
Dies ermöglicht uns eine echtzeitnahe Gestenerkennung.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Anwendung auf das Projekt}
Zur Klassifikation der Gesten wird eine \ac{SVM} benutzt, die mit geringfügig angepassten und von den Standards des verwendeten Python-Moduls abweichenden Werten der entsprechenden Parameter trainiert wird. 
Für das Training erwartet die \ac{SVM} neben einem Eingabevektor mit 320 Werten noch die dazugehörige Klasse.
Während der Live-Klassifikation von Gesten, beziehungsweise deren Eingabevektoren, wird die trainierte \ac{SVM} für die Erkennung verwendet.
Die Eingabevektoren müssen dabei in ihrer Dimension den Trainingsdaten entsprechen.

Der nächste Abschnitt widmet sich der Datenaufbereitung, insbesondere der Reduzierung der Dimension eines Eingabevektors und der entsprechenden Vorverarbeitung.

\begin{figure*}[htbp] \centering
    \includegraphics[width=0.65\textwidth]{svm/svm_preprocessing_steps.png}
    \caption{Datenaufbereitungsschritte}
    \label{fig:svm_preprocessing_steps}
\end{figure*}

\subsubsection{Datenaufbereitung}\label{sec:svm_data} 
In \autoref{sec:intro} wurde die Aufnahme und die generelle Vorverarbeitung der Daten bereits erläutert, bevor diese an die entsprechenden Klassifikatoren weitergeleitet werden.
Da jeder Klassifikator aufgrund seiner Funktionsweise unterschiedlich mit den Eingabedaten arbeitet, ist eine entsprechende und auf den jeweiligen Klassifikator angepasste Datenaufbereitung notwendig.
Gleichzeitig kann durch eine entsprechende Vorverarbeitung gegenüber unverarbeiteten Daten das Problem der Klassifikation von unterschiedlichen Datensätzen verallgemeinert und somit die Trainingszeit verringert werden.
Dieser Abschnitt befasst sich mit der spezifischen Datenaufbereitung für den \ac{SVM}-Klassifikator. 
Eine entsprechende grafische Visualisierung aller Datenaufbereitungsschritte befindet sich in \autoref{fig:svm_preprocessing_steps}.

\paragraph{Eingabevektordimensionsreduzierung}\label{sec:svm_reduce}$\;$ \\
Bei der Betrachtung der Trainingsdaten, die jeweils aus insgesamt 32 Frames zu je 64 Werten bestehen, wird offensichtlich, dass die durch den Doppler-Effekt verursachten Frequenzverschiebungen in einem begrenzten Umfeld der Referenzfrequenz von $18\text{,}5\text{ kHz}$ herum sattfinden.
Zudem stellt sich heraus, dass nur ein Bruchteil der ursprünglich veranschlagten 32 Frames pro Geste relevante Informationen enthält, da die Ausführung einer Geste meist zwischen 8 und 20 Frames dauert und nur innerhalb dieser Frame-Anzahl Frequenzverschiebungen verursacht.
Aufgrund dieser beiden Gründe werden im ersten Schritt der Reduzierung der verwendete Wertebereich eines Frames von 64 auf 40 verkleinert und im nächsten Reduzierungsschritt sowohl für das Training der \ac{SVM} als auch für die Live-Klassifikation nur 16 Frames pro Geste verwendet. 

Die dritte Reduzierung wird mittels der Addition benachbarter Frames erzielt, so dass letztlich nur noch jeweils 8 Frames zu je 40 Werten pro Datensatz/Geste existieren.
Im Anschluss erfolgt die Transformation in ein eindimensionales Array mit insgesamt 320 Werten, welches als Eingabevektor für die \ac{SVM} dient.
Gegenüber der ursprünglichen Gesamtanzahl von 2048 Werten pro Datensatz wurde mittels der Vorverarbeitung die Dimension eines Eingabevektors um etwa den Faktor $6\text{,}5$ verringert.
Eine weitere Reduzierung um den Faktor 2 ist möglich, sofern nur jeder zweite Wert des Eingabevektors verwendet werden soll.

\paragraph{Vorverarbeitung}\label{sec:svm_preprocess}$\;$ \\\\
Die Reduzierung der Eingabevektordimension und die vorverarbeitenden Schritte sind zwei notwendige Handlungen, die sich in der Implementierung nicht trennen lassen, allerdings sind sie in ihrer Beschreibung gut zu separieren.
Unmittelbar nach dem ersten Reduzierungsschritt wird jeder einzelne Frame normalisiert und die Referenzfrequenz subtrahiert.
Da trotz Subtraktion der Referenzfrequenz teilweise noch sehr feines Rauschen in den Daten vorhanden sein kann, werden Werte unterhalb eines festgelegten Schwellenwerts auf 0 gesetzt.
Die ersten 16 Frames, die nach diesem Verarbeitungsschritt relevante Informationen enthalten (Frame-Maximalwert \textgreater 0), werden für den dritten Reduzierungsschritt verwendet.
Optional und standardmäßig aktiviert wird eine eindimensionale Gauß'sche Filterung zur Glättung der Werte als abschließender Vorverarbeitungsschritt angewandt.

\subsubsection{Implementierung}\label{sec:svm_implementation}
Aufgrund des Einsatzes von verschiedenen Klassifikatoren ist ein gemeinsames Interface für alle Klassifikatoren vorhanden, welches von jedem Klassifikator -- allerdings unterschiedlich -- implementiert ist. 
Dabei handelt es sich um die abstrakte Klasse \texttt{IClassifier}, die von der \ac{SVM}--Klasse im Modul \texttt{svm.py}  implementiert werden muss.

\begin{lstlisting}[float=*,language=Python,caption={Code Snipplet},label={lst:svm_code_snipplets}]{lst:svm_code_snipplets}
def preprocess_frame(frame_data):
	try:
		''' slice frame data if necessary '''
		if frame_data.shape[0] == wanted_frames:
			frame = frame_data
		else:
			frame = slice_frame(frame_data)

		''' normalise frame '''
		normalized_data_with_ref_frequency = frame / np.amax(frame)
		normalized_data = normalized_data_with_ref_frequency - ref_frequency_frame

		''' set small noisy data to 0 '''
		frame = normalized_data
		irrelevant_samples = np.where(frame <= threshold)
		frame[irrelevant_samples] = 0.0
	except:
		frame = np.zeros(wanted_frames)
	return frame
\end{lstlisting}


Für die Implementierung der \ac{SVM}--Klasse wird die Python-Bibliothek \textit{scikit-learn} verwendet. 
Die Bibliothek stellt neben einer Vielzahl von weiteren Modulen und Klassen unter anderem auch eine Implementierung einer \ac{SVM} zur Verfügung.
Für grundlegende Matrizenberechnungen in den Modulen \texttt{svm\_dataloader.py} und \texttt{svm\_preprocessor.py} werden die Python-Bibliotheken \textit{NumPy} und \textit{SciPy} verwendet. 
\textit{NumPy} zeichnet sich vor allem durch effiziente Berechnungsoperationen und eine Vielzahl an nützlichen Funktionen aus, die durch das Erweiterungsmodul \textit{SciPy} um weitere sinnvolle Methoden ergänzt werden.
Zusätzlich findet das in der Python-Installation enthaltene \textit{os}-Modul Einsatz, um grundlegende Dateipfadkonkatenationen zu bewerkstelligen.
Letztendlich wird das ebenfalls standardmäßig in der Python-Installation enthaltene \textit{subprocess}-Modul verwendet, um mittels erkannter Gesten verschiedene Programme starten und beenden zu können.
Diese Funktionalität ist in einem separaten Modul \texttt{svm\_appstarter.py} ausgelagert.
Grundlegende Konfigurationseinstellungen, die das Verhalten der \ac{SVM} oder die Vorverarbeitung steuern, sind in einer separaten Konfigurationsdatei ausgelagert und werden bei der Initialisierung des Programms bzw. der Klassifikatormodule geladen.

Die Trainingsmethode \texttt{startTraining} ruft zuerst die \texttt{loadData}-Methode auf, um die Datensätze zu laden und entsprechend vorzuverarbeiten.
Das Einlesen übernimmt dabei eine entsprechende Methode der \texttt{Dataloader}-Instanz und die vorverarbeitenden Schritte die \texttt{Preprocessor}-Instanz.
Diese Datensätze werden inklusive den entsprechenden Klassenzugehörigkeiten der \texttt{fit()}-Methode der \ac{SVM}-Klassifikatorimplementierung zum Training übergeben.
Dieser Klassifikator wurde davor bereits mit den in der Konfigurationsdatei festgelegten Parametern initialisiert.
Nach dem Training wird eine globale Referenz auf die trainierte \ac{SVM} gespeichert.
Gleichzeitig wird die trainierte \ac{SVM} auf der Festplatte für spätere Aufrufe komprimiert gespeichert, so dass nach einem Neustart des Programms das Training nicht erneut ausgeführt werden muss.

Die Klassifikationsmethode \texttt{classify} erhält von dem Hauptprogramm jeweils einzelne Frames zu je 64 Werten, die sich innerhab des Frequenzbereichs um die Referenzfrequenz von $18\text{,}5\text{ kHz}$ befinden.
Anschließend wird direkt der erste beschriebene Vorverarbeitungsschritt pro übergebenem Frame ausgeführt, die in einer globalen Liste \texttt{datalist} abgespeichert werden.
Mittels einer Abfrage, ob der Frame überhaupt relevante Informationen besitzt, wird der Gestenanfang erkannt und der entsprechende Index der Liste \texttt{datalist} gespeichert.
Sobald 32 weitere Frames in dieser Liste abgespeichert worden sind, werden 16 relevanten Frames ab dem Startpunkt -Index herausgesucht und mittels der weiteren Vorverarbeitungsschritte zu einem Eingabevektor mit 320 Werten transformiert.
Der Eingabevektor wird dem Klassifikator übergeben, welcher als Rückgabewert die entsprechende Gestennummer zurückliefert, die er dem Eingabevektor zugeordnet hat.
Gleichzeitig dient diese Gestennummer zur Steuerung von diversen Programmen.
So kann mittels dem entsprechenden Methodenaufruf der \texttt{Appstarter}-Instanz und der beispielsweise übergebenenen Gestennummer 0 der Notepad-Editor geöffnet und mittels der Gestennummer 1 wieder beendet werden.

\subsubsection{Training}\label{sec:svm_training}
Für das Training werden die Datensätze aller Gesten von zwei Personen verwendet.
Dadurch ergibt sich eine relativ geringe Gesamtanzahl der Datensätze von etwa 1200.
Der Grund für das Nichtverwenden aller Daten liegt in der Qualität der Trainingsdaten, die durch verschiedene Hardwarekonfigurationen der einzelnen Laptops in Bezug auf Lautsprecher und Mikrofon oder auch durch die inkorrekte Ausführung der Gesten teilweise nicht sehr gut ist.
Mit der Entscheidung, nur Datensätze von zwei Personen zu verwenden, ergibt sich allerdings automatisch die Chance zu mehr Übereinstimmungen.
Das Training wird aufgrund der geringen Anzahl von Trainingsdaten und der reduzierten Eingabevektordimension in kurzer Zeit ausgeführt.
Dabei wird durch das Festlegen entsprechender Parameter in der Konfigurationsdatei das Training maßgeblich beeinflusst. 

Mittels des Parameters $C$ lässt sich die Margin-Breite $m$ der Hyperebene steuern.
Je größer dabei $C$ wird, desto kleiner wird der Margin-Wert und desto mehr wird von einer Überanpassung (engl. Overfitting) gesprochen.
Bei der Verwendung von sehr kleinen Werten von $C$ können allerdings sogar Trainigsdaten falsch klassifiziert werden, die linear separierbar sind.
Ein hoher Wert für den Parameter $gamma$ führt in Kombination mit einem hohen Wert für $C$ zu einem starken Overfitting an die Trainingsdaten.
==[degree]
==[coef0]

Die Werte in der Konfigurationsdatei sind für ein geringes Overfitting der \ac{SVM} an die Trainingsdaten bekannt und sind in folgender Tabelle (\autoref{tab:svm_parameter}) in der zweiten Zeile aufgelistet.
Die von dem Python-Modul \texttt{scikit-learn} vorgegebenen Standardwerte befinden sich in der ersten Zeile der selben Tabelle.

\begin{table}[h]
\centering
\begin{tabular}{rrrr}
\hline
  \multicolumn{1}{c}{\textbf{C}} & \multicolumn{1}{c}{\textbf{gamma}} & \multicolumn{1}{c}{\textbf{degree}} & \multicolumn{1}{c}{\textbf{coef0}} \\
 \hline
 1.0 & 0.00 & 3 & 0.0 \\
 \hline
 10.0 & 0.25 & 3 & 0.0 \\
\hline
\end{tabular}
\caption[Parameter für das Training einer SVM]{Parameter für das Training einer SVM}
\label{tab:svm_parameter}
\end{table}


\subsubsection{Evaluation}\label{sec:svm_evaluation}
Sofern die \ac{SVM} zur Live-Klassifkation eingesetzt wird, ist die Verwendung des kompletten Datensatzes für das Training unbedenklich.
Die Validierung einer mit dem kompletten Datensatz trainierten \ac{SVM} mit dem gleichen kompletten Datensatz führt allerdings unweigerlich zu einer Verfälschung der Performance.
Sobald demnach eine prozentuelle Einordnung der Performance einer trainierten \ac{SVM} erwünscht ist, bietet es sich an, den kompletten Datensatzumfang in zwei Teile im Verhältnis $\frac{2}{3}$ zu $\frac{1}{3}$ zu unterteilen und das Training mit dem knapp 800 Datensätze fassenden ersten Teil auszuführen.
Der zweite Datensatzteil dient der Validierung bzw. dem Testen der trainierten \ac{SVM}.

\begin{figure}[htbp] \centering
    \includegraphics[width=0.3\textwidth]{svm/svm_confusion_matrix.png}
    \caption{Visuelle Darstellung einer Confusion Matrix}
    \label{fig:svm_confusion_matrix}
\end{figure}

\begin{table}[h]
\centering
\begin{tabular}{lrr}
\hline
 \multicolumn{1}{c}{\textbf{Gesture}} & \multicolumn{1}{c}{\textbf{Prec.}} & \multicolumn{1}{c}{\textbf{Recall}} \\
 \hline
  0: \texttt{\ac{RLO}} & 87\% & 92\% \\
 \hline
  1: \texttt{\ac{TBO}} & 97\% & 97\% \\
 \hline
  2: \texttt{\ac{OT}} & 100\% & 92\% \\
 \hline
  3: \texttt{\ac{SPO}} & 93\% & 83\% \\
 \hline
  4: \texttt{\ac{DPO}} & 93\% & 93\% \\
 \hline
  5: \texttt{\ac{RO}} & 77\% & 88\% \\
 \hline
  6: \texttt{\ac{BNS}} \& \ac{BNN} & 96\% & 100\% \\
 \hline
  Average & 92\% & 92\% \\
 \hline
\end{tabular}
\caption[Erkennungsraten einer SVM]{Erkennungsraten einer SVM}
\label{tab:svm_performance}
\end{table}

Durch die Wahl der in \autoref{sec:svm_training} vorgestellten Parameter wird die Fehlerrate in der Validierung auf 8\% minimiert.
Obwohl meist eine allgemeinere Klassifikation ohne Overfitting gewünscht ist, zeigt sich bei der Live-Klassifikation ein ähnliches Bild.
So werden die meisten ausgeführten Gesten direkt der korrekten Klasse zugeordnet.


\subsubsection{Fazit}\label{sec:svm_conclusion}
\ac{SVM}s zeigen, dass sie selbst bei der Verwendung von einer recht niedrigen Anzahl von verwendeten Trainingsdaten in der Lage sind, gute Klassifikationsergebnisse zu erzielen.
Weitere Vorteile von \ac{SVM}s bestehen darin, dass die Trainingsphase schnell absolviert und durch die Wahl entsprechender Parameter direkt Einfluss auf die Validierungsergebnisse genommen werden kann.
So liefert der trainierte \ac{SVM}-Klassifikator sehr gute Ergebnisse in der Validierung, da die Fehlerrate auf 8\% minimiert werden konnte.
Ausgenommen von zwei Gesten zeigte es sich allerdings, dass die Performance in der Live-Klassifikation trotz vermeintlichem Overfitting erstaunlich gut ist.
Bei den zwei Gesten, die nicht immer zuverlässig erkannt werden, handelt es sich um Geste 2 \ac{OT} und Geste 5 \ac{RO}.
==[wieso]

Allgemein lässt sich die Performance des Klassifikators vor allem durch eine gute Vorverarbeitung und Merkmalsextraktion positiv beeinflussen.
Allerdings erschweren qualitativ unterschiedlich gute Trainingsdatensätze die Vorverarbeitungs- und die Trainingsphase und beeinflussen somit stark die Validierungs- und die Live-Klassifikationsergebnisse
Ursache dafür sind vermutlich die verschiedenen Laptops mit ihrer unterschiedlichen verbauten Hardware bezüglich Lautsprecher und Mikrofon.
Auch das nicht korrekte Ausführen der Gesten bei der Aufnahme für das Erstellen der Trainingsdatensätze ist eine Fehler- bzw. Problemquelle.
So erfordert die aktuelle Vorverarbeitungsstrategie eine recht exakte Ausführung der Geste unter sehr guten Vorraussetzungen.
Laute Umgebungsgeräusche sollten vermieden werden (dies kann jedoch auch an der aktuellen Hardwarekonfiguration des Testgeräts liegen), da das Mikrofon überempfindlich reagiert und teilweise selbst normale Musik oder Umgebungsgeräusche Schwankungen im Frequenzspektrum rund um die Referenzfrequenz von 18.500 kHz verursacht.
