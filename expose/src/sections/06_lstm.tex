\section{\acl{LSTM}}
\textit{Daniel Andrés López, Frank Reichwein}

Eine weitere Art eine Klassifizierung vorzunehmen ist es ein neuronales Netz zu
verwenden. Dieser Ansatz ist durch die Biologie motiviert und lehnt sich an die
Arbeitsweise eines Gehirns an. Im Gehirn sind Neuronen über Synapsen iteinander
verbunden. Nervenbahnen aus dem gesamten Körper erreichen die Neuronen und
stimulieren sie in unterschiedlicher Intensität. Wird dabei ein Schwellwert
überschritten ist dieses Neuron aktiviert und sendet ebenfalls einen Impuls an
die mit ihm über die Synapsen verbundenen Neuronen. Dies geschieht fortlaufend.
Die Synapsen sind jedoch unterschiedlich stark ausgeprägt, um auch eine
unterschiedliche Stimulierungsintensität weiterzugeben. Dies kommt einer
Gewichtung der Neuronen gleich, da die Eingangssignale einen unterschiedlich
starken Einfluss auf das stimulierte Neuron haben. Die Synapsen sind jedoch
nicht fest und von vornerein vorgegeben. Sie werden kontinuerlich auf- und
abgebaut bzw. verändert. Diesen Vorgang wird im Allgemeinen Lernen bezeichnet.
Die erlebten Erfahrungen werden in dem Netz von Neuronen und Synapsen
verarbeitet und dadurch gespeichert. Erreichen das Gehirn nun neue
Sinneseindrücke werden die Neuronen erneut stimuliert und je nach Ergebnis
werden bestimmte Erinnerungen, Gefühle, Aktionen oder anderes erlebt und
ausgeführt. Jedoch sind sie nicht direkt an ein bestimmtes Ereignis geknüpft,
sondern wurden durch verschiedene Erfahrungen verallgemeinert, um so
verschiedenen Situationen gut verarbeiten zu können. 

\paragraph{Modelle von Neuronen und Synapsen}
Im Bereich des maschinellen Lernen wird versucht die Funktionsweise eines
Gehirns bzw. Netzes aus Neuronen und Synapsen nachzubilden. Dies wird durch
vereinfachte Modelle von Neuroen und Synapsen erreicht. Als Grundlage dient
dabei das Modell von McCulloch und Pitts von 1943 (vgl. \cite{Mcc43}). Es
modelliert ein Neuron mit $n$-vielen Eingabewerten ($x_1,\ldots,x_n$) und einem
Ausgabewert $y$. Die Eingabewerte entsprechen der Aktivierung eines
Vorgängerneurons und der Ausgabewert der Aktivierung des betrachteten Neurons.
\textbf{TODO Picture McCulloch and Pitts Neuron} Die \autoref{} zeigt den Aufbau
eines solchen Neurons. Die Eingaben weren dabei zuerst im \textit{Addierer}
summiert, eine Schwellwertfunktion (bzw. allgemeiner eine Aktivierungsfunktion)
bestimmt dann mit der Summe den Ausgabewert (die Aktivierung) des Neurons. De Weiteren
werden auch die Synapsen nachgebildet in dem jeder Eingabewert bei der
Summierung individuell gewichtet wird. Die Gewichte entsprechen den
unterschiedlich stark ausgeprägten Synapsen. Das klassische Modell erlaubt nur
binäre Ein- und Ausgaben, dies kann jedoch auf Reelle Zahlen erweitert werden,
um unterschiedlich starke Stimulierungen bzw. auch negative Werte (Hemmungen)
zuzulassen.

\paragraph{Neuronale Netzwerke}
Einzelne Neuronen können allerdings kein Gehrin nachbilden. Aus diesem Grund ist
di Kombination mehrerer Neuronen zu einem neuronalen Netz nötig. Im einfachsten
Fall entsteht dabei ein \textit{Perzeptron}. Es werden $n$-viele Neuronen
verwendet. Alle Eingaben werden von allen Neuronen verarbeitet und jedes Neuron
hat eine eigene Aktivierung. Die Gewichte (Synapsen) sind individuell für jedes
Neuron. Die Ausgaben ergeben den Ausgabevektor $\bf{y}$ des Netzwerkes. Um
komplexere Sachverhalte darstellen zu können ist es nötig Neuronen in
Abhängigkeit voneinander zu betrachten. Dies wird in \acp{MLP} vorgenommen.
Mehrere Perzeptrons werden hintereinandergeschaltet, sodass die Ausgabe des
einen Perzeptrons (ein Layer) die Eingabe des nächsten Perzeptrons ist.
Lediglich die Ausgabe des letzten Perzeptrons ist die Ausgabe des Netzwerks. 
Ein Netzwerk kann als gerichteter Graph dargestellt werden. Die Richtung
entspricht dem Datenfluss. Perzeptrons und \acp{MLP} sind azyklische Graphen,
d.h. die Verbindungen von Neuronen gehen nur in Vorwärtsrichtung und bilden
somit keinen Kreis. Daher werden diese Netzwerke \textit{Feedforward}-Netzwerke
genannt. Um besser die Funktionsweise von Gehirnen nachzubilden ist es
notwendig auch Verbidnungen von Neuronen auf sich selbst zuzulassen. Somit
entsteht ein zyklischer Graph und das Netzwerk wird zu einem Rekurrenten
Neuronalen Netz (\acsu{RNN}). 
\textbf{TODO Bilder von Neuronalen Netzen zur Verdeutlichung}

In den folgenden Kapiteln wird eine Sonderform von \acp{RNN} verwendet, ein
\ac{LSTM}. Dazu wird zuerst darauf eingegangen wie ein \ac{LSTM} im
Allgemeinen funktioniert und wie ein solches Netzwerk trainiert werden kann.
Darauf aufbauend wird das Verfahren auf das Projekt angepasst. Es werden die
Datenaufbereitung, die Anpassung des Klassifikators, die Implementierung in
Python, das Training und eine Evaluierung besprochen. 


\subsection{Funktionsweise des Klassifikators (Allgemein)}

Ein spezielles \ac{RNN} ist ein \acl{LSTM}. Es wurde 1997
vorgestellt\cite{Hochreiter:1997}. Wie allgemein Neuronale Netze und
insbesondere \ac{RNN} können auch \ac{LSTM}-Netze biologisch motiviert werden.
Neuronen im Gehirn verhalten sich nicht mit der gleichen Eingabe gleich.
Vielmehr reagieren sie abhängig von verschiedenen Situationen anders. Beinflusst
wird dies durch vorangegangene Ereignisse. Eindrücke (Eingaben) werden so in
einen zeitlichen Bezug gestellt und dadurch entseht eine zusammenhängende
Erinnerung. Diese wird wie eine einzelne Eingabe ebenfalls generalisiert in den
Synapsen und Neuronen gespeichert. Mit Hilfe der \ac{LSTM} Architektur wird
versucht dieses Verhalten nachzuahmen. 

\subsection{Anwednug auf Projekt}
Für das Projekt wurde ein LSTM-Netz erstellt welches konfiguriert wurde:

\begin{itemize}
\item \textbf{Input Layer} Das Netzwerk hat 64 Inputs.
\item \textbf{Hidden Layer} Für das Hidden Layer werden 18 LSTM-Neuronen verwendet.
\item \textbf{Output Layer} Das Output Layer besteht aus 7 Neuronen, die die 
Softmax Funktion als Aktivierungsfunktion verwenden.
\end{itemize}

\begin{figure}[htbp]
    \centering
   \includegraphics[height=50mm]{lstm/lstm_netz}
\caption{LSTM-Netz}
\label{fig:lstm_netz}
\end{figure}


\subsubsection{Datenaufbereitung}
\label{sec:lstm_data}

In Kapitel \ref{Kapitel 1 TODO} wird beschrieben wie die Daten aufgenommen und
im Allgemeinen verarbeitet werden, bevor sie den Klassifikatoren zur
Verfügung gestellt werden. Diese erhalten jeweils einzelne Frames mit je 64
Daten. Die Daten entprechen dem Frequenzspektrum im Umfeld der
Referenzfrequenz von $18500\text{kHz}$. Eine Geste wurde mit 32 Frames
aufgenommen. Für \ac{LSTM}-Netzwerke sind diese rohen Daten eher ungeignet. Die
Netzwerke können zwar im Allgemeinen mit unverarbeiteteten Daten umgehen,
tortzdem ist ein Vorverarbeitung sinnvoll, da sich dadurch die Verallgemeinerung
des Problems verbessert, die Trainingszeit verkürzt und die benötigten Beispiele
verringern \textbf{Cite}. Aus diesen Gründen wird eine Vorverarbeitung der Daten
vorgenommen. 

Die Beispieldaten sind auf verschiedenen Hardwareplattformen mit
unterschiedlichen Lautstärke und Aufnahmelautstärke Konfigurationen erzeugt
worden. Der Wertebereich dieser Daten ist somit groß und unterschiedlich bei
gleichen Gesten. Das Problem dass durch diese Varianz der Wertemenge entseht
ist, dass \acp{LSTM} Netze (bzw. jede Form von neuronalen Netzen) die Gewichte
entsprechend groß kalibirieren muss, um Unterschiede ausgleichen zu können und
eine verallgemeinertes Ergebnis zu liefern. Da jedoch das (später beschriebene)
Trainigsverfahren iterativ die Gewichte in kleinen Schritten anpasst, führen
große Gewichte zu einem hohen Trainingsaufwand. Um dies zu vermeiden werden die
Daten normalisiert. Konkret wird dabei der Maximalwert eines Frames als
Normierungsfaktor gewählt. Dadurch liegen alle Werte im Intervall $[0,1]$.
Eine Transformation \textbf{richtiges Wort?} des SPektrums hin zu den
Veränderungen der Spektrums im Vergleich zum Ruhespektrum wird ebenfalls
vorgenommen. Dies wird aufgrund durchgeführter Tests vorgenommen, die eine
bessere Klassifizierungen für die transformierten Daten bescheinigen
(\textbf{Tests einbinden}). Der allgemeine Ruhezustand wird aus den Beispielen
des Ruhzustands (Geste 6 und 7) durch das normalisierte Mittel gewonnen. Der
Ruhezustand wird dann von jedem Beispiel abgezogen. Es werden hierbei lediglich
die Beispiele verwendet, denkbar ist jedoch auch die Aufnahme des Ruhezustands
auf dem Zielgerät, um spezifischere Daten zu erhalten. 

Bei der Betrachtung der Daten fällt auf, dass der Doppler-Effekt in einem
kleinen Intervall um die Referenzfrequenz auftritt und die Daten außerhalb
dieses Intervalls keine große Bedeutung spielen. Aus diesem Grund ist eine
Verkleinerung der Frame Größe in Betracht zu ziehen. Da jedoch eine manuelle
Betrachtung aller Daten nicht möglich ist, lässt sich diese Beobachtung nicht
verifzieren. Daher werden mehrere \ac{LSTM}-Netze mit unterschiedlichen
Inputframelängen trainiert und die Ergebnisse verglichen. \textbf{TODO Tabelle
mit Ergebnissen} Erstaunlicherweise ist die aufgestellte Vermutung falsch und die
Netzwerke ohne zugeschnittenen Trainingsdaten klassifizieren besser. 

Eine weitere Beobachtung die gemacht werden kann ist, dass benachbarte
Datenpunkte sich nicht wesentlich unterscheiden. Dies kann genutzt werden um die
Eingabedimension zu verringern, indem z.B. jeweils zwei benachbarte Datenpunkte
miteinander addiert werden. Dies kann auch mit dem verkleinern der Frames
kombiniert werden. Um den Einfluss auf das Klassifierzungsverhalten von
\ac{LSTM}-Netzen zu zeigen sind auch hier Tests durchgeführt worden.
\textbf{TODO Tabelle mit Ergebnissen} Das Ergebnis zeigt, dass die Netze ohne
die Summe benachbarter Werte besser klassifizieren als mit der Summe. 

Weitere Methoden der Datenvorverarbeitung wurden ebenfalls untersucht, jedoch
hat dies die Ergebnisse ebenfalls negativ beeinflusst, weshalb sie nicht näher
betrachtet wurden. Darunter fällt u.a. die statische Eliminierung von Rauschen.
Diese Methode setzt jeden Wert der unter einem bestimmten Schwellwert ist zu 0,
da dies kein signifikanter Beitrag zur Geste ist sondern ein Rauschen. Das
Ergebnis dieser Untersuchung ist jedoch unbefridigend, sodass die Idee nicht
genutzt wird. \textbf{TODO Messwerte?}



\subsubsection{Anpassung des Klassifikators}
\subsubsection{Implementierung}
Da es zum Ende des Projektes ein Programm geben soll, indem alle Klassifikatoren 
eingebunden sind, haben sich alle Teilnehmer auf ein Interface geeingtt, was 
jeder Klassifikator implementieren muss. Dies ist die abstrakte Klasse \textit{IClassifier}.

\textbf{TODO Klassendiagramm}

Die Implementation des \ac{LSTM}-Klassifikators ist in der Klasse LSTM zu finden.
Für diese wurde \cite{PyBrain} verwendet. Diese Bibliothek stellt verschiedene
Machine Learning Algorithmen bereit, unter anderem Neuronale Netzwerke mit 
\ac{LSTM}-Neuronen.
Außerdem wurden in der Datei util verschiedene Hilfsfunktionen erstellt.
Des weiteren werden Konfigurationseinstellungen in einer Datei gespeichert und zur 
initialisierung der geladen. 
Da beabsichtigt ist mit dem Programm den PC zu steuern, wurde die Python Bibliothek 
\cite{Python-uinput} eingebunden. Mit dieser können Keycodes an den Kernel geschickt werden.
Die Bibliothek funktioniert nur unter Linux und erfordert Root-Rechte.
Im folgenden wird auf die Implementation der einzelnen MEthoden der 
\textit{IClassifier}-Klasse eingegangen.

\subsubsection*{Live Klassifikation}
Für die Live Klassifikation wurde zwei verschiedene Ideen implementiert. 
Bei beiden wird zuerst die \textit{classify} Methode der LSTM-Klasse 
aufgerufen. Diese bekommt den Datensatz der aktuellen Aufnahme übergeben. 
Der Datensatz enthält ein Array mit 64-Datenpunkten. Die übergebenen Daten werden 
Normalisiert und anschließend wird der Durchschnitt abgezogen, wie in Kapitel 
\autoref{sec:lstm_data} beschrieben. Nachdem die Daten vorbearbeitet wurden, 
werden diese einer \textit{classify1}-Methode übergeben. 
\begin{lstlisting}[language=Python,caption={Classify
Variante 1},label={lst:lstm_classify1}]{lst:lstm_classify1}
def __classify1(self,data):
	self.datalist.append(data)
	self.datanum += 1
	if(self.datanum % 32 == 0):
		self.net.reset()
		out = self._activateSequence(self.datalist)
		print(str(out))
		self.datalist = []
		self.datanum = 0
		return out
	return -1
\end{lstlisting}

Die Methode \textit{classify1} speichert so lange die übergebenen Datenwerte, 
bis 32-Werte aufgenommen wurden. Diese 32-Werten werden dem \ac{LSTM}-Netz 
übergeben und eine Klassifikation gestartet. Da es bei diesem Ansatz passieren kann, 
dass eine Geste nicht komplett in diesen 32-Werte enthalten ist, wurde ein zweite 
Idee umgesetzt, welche in der Methode \textit{classify2} umgesetzt ist.

\begin{lstlisting}[language=Python,caption={Classify
Variante 2},label={lst:lstm_classify2}]{lst:lstm_classify2}
def __classify2(self, data):
	self.datanum += 1
	self.datalist.append(data)
	if(self.datanum % 32 == 0):
		self.has32 = True
	if(self.has32):
		self.net.reset()
		Y_pred = self._activateSequence(self.datalist)
		del self.datalist[0]
		self.predHistory[0] = Y_pred
		self.predHistory = np.roll(self.predHistory, -1)
		expected = stats.mode(self.predHistory, 0)
		if(expected[1][0] >= self.predHistHalfUpper):
			if(int(expected[0][0]) != self.previouspredict):
				oldPrevious, oldPredCounter = self.previouspredict, self.previouspredict
				self.previouspredict = int(expected[0][0])
				self.predcounter = 1
				return oldPrevious, oldPredCounter
			else:
				self.predcounter += 1
				if(self.predcounter == 4):
					print(str(self.previouspredict))
					self.outkeys.outForClass(self.previouspredict)
				return self.previouspredict, self.predcounter
	return -1, -1
\end{lstlisting}

Die Methode \textit{classify2} speichert so lange die übergebenen Datenwerte, 
bis 32-Werte aufgenommen wurden. Diese 32-Werten werden dem \ac{LSTM}-Netz 
übergeben und eine Klassifikation gestartet. Die erkannte Geste wird in einer 
Liste gespeichert. Von dieser Liste wird, mittels der Python-Funktion mode, 
der Wert ermittelt der am häufigsten vorkommt. Ist dieser Wert größer als eine 
definierte Schranke wird er in \textit{previouspredict} gespeichert. Wenn vier 
mal hinter einander die gleiche Geste erkannt wurde, wird diese ausgegeben.

\subsubsection{Training}
Für das Trainieren von Neuronalen Netzen bietet PyBrain verschiedene 
Trainer an:
\begin{itemize}
\item BackpropTrainer
\item RPropMinusTrainer
\end{itemize}
Da der RPropMinusTrainer eine Erweiterung des BackpropTrainer ist, wurde mit 
diesem trainiert. Für die verwendung der zu verfügung gestellten Trainer 
muss ein PyBrain Dataset erstellt werden. Um dieses zu erstellen wurde eine 
Methode geschrieben. Diese erstellt aus den Aufnahmen ein Dataset. Dazu wird 
aus den Aufnahmen ein Array generiert. Nach der generierung werden die Daten 
normalisiert. Anschließend werden noch weitere Schritte durchgeführt, diese 
sind in Kapitel \autoref{sec:lstm_data} beschrieben und können mit den folgenden 
Parametern konfiguriert werden:
\begin{itemize}
\item \textbf{merge67} Dieser Parameter gibt an, ob die Gesten 6 und 7 
zusammengefasst werden sollen.
\item \textbf{average} Definiert ob nach der Normalisierung der Datensätze der 
Durchschnitt abgezogen wird. 
\item \textbf{cut} Gibt an um wieviel jeder Datensatz beschnitten wird.
\item \textbf{fold} Konfiguriert ob jeder der Datensätze verwendet wird oder
wieviele übersprungen werden.
\end{itemize} 
Nach der Erstelung des Datasets wird es gespaltet. Für das Training werden 
80\% und für die Validierung 20\% verwendet.

Für die Validierung des Netzes wurde eine Methode implementiert, die anahnd 
des Testsets validiert wie gut das Neuronale Netzwerk die Gesten erkennt. Nach 
diesem Test wird eine Matrix erstellt, die die Anzahl der richtig erkannten Gesten 
sowie die Anzahl der falsch erkannten Gesten anzeigt. 

\textbf{TODO MAtrix anzeigen}

\subsubsection{Evaluation}

\subsection{Fazit}
- LSTM (NN) können Eingaben nur synchron verarbeiten und nicht asynchron wie ein
Gehrin
- zusätzliche Einflüsse wie Botenstoffe die sich auf die Neuronenaktivität
auswirken werden ebenfalls nicht nachgebildet. 

\nocite{schaul2010,GERS2001,WIKI2013,Schmidhuber2013,LSTM1,Nerbonne1}
