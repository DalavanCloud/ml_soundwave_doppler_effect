\section{\acl{HMM}}
\textit{Paul Pasler, Sebastian Rieder}

Das \acl{HMM} ist ein stochastisches Modell für sequentielle Daten und wird vor allem in der Spracherkennung und in der Bioinformatik eingesetzt.

Grundlage des \acl{HMM} waren die nach dem russischen Mathematiker Andrej Andrejewitsch Markov 
(1856 - 1922, siehe \cite{wiki:markov}) benannten Markov-Modelle. Zu Beginn des 20. Jahrhunderts 
beschäftigte er sich als erster mit einer statistischen Beschreibung von Zustands- und Symbolfolgen. 
Er führte eine statistische Analyse der Buchstabenfolge des Textes ``Eugen Onegin'' von Alexander 
Pushkin.

Der amerikanischen Mathematiker Leonard E. Baum (* 1931) und andere Autoren erweiterten dieses Konzept Ende der 
sechziger Jahre und nannten es \acl{HMM}. Erste \acl{HMM}-Applikationen wurden zur Spracherkennung und später auch in der Bioinformatik 
zur Analyse von Nukleotid- und Proteinsequenzen eingesetzt. 
 
\subsection{Markov-Ketten}
Markov-Ketten beschreiben einen speziellen stochastischen Prozess, der aufgrund der Vorgeschichte Aussagen über die Zukunft macht.
Bei Markov-Ketten 1. Ordnung benötigt man für diese Aussagen nur den gegenwärtigen Zustand.


Eine Markov-Kette ist definiert durch eine endlich Menge an Zuständen \( S = \{ s | 1 <= s <= N \} \) und der diskreten Zeit \( t = 0, 1, 2, \ldots \) \\
\textbf{1. Markov Eigenschaft: } \\
\( \forall t \in \mathbb{N} : P (X_t = x_t | X_1 = x_1 ; \ldots ; X_t_-_1 = x_t_-_1 ; Y_1 = y_1 ; \ldots ; Y_t_-_1 = y_t_-_1 ) = P (X_t = x_t | X_t_-_1) \) \\


\subsection{\acl{HMM} und \acl{GMM}}
\acl{HMM} erweitern das Konzept der Markov-Ketten um eine zustandsspezifische Ausgabe und eine statistisch 
modellierte Zustandsfolge.

Ein \acl{HMM} ist eindeutig definiert durch:\\ 
\( \lambda = (S;V;A;B;\pi)\)
\begin{itemize}
     \item Endlich Menge von Zuständen \\
           \( S = \{ s | 1 <= s <= N \} \)
     \item Alphabeth der Emissionen \\
           \( V = \{ v | 1 <= v <= M \} \)
     \item Matrix der Zustandsübergangswahrscheinlichkeiten \\
           \( A = \{ a_i_j | a_i_j = P(S_t = j | S_t_-_1 = i) \} \)
     \item Matrix der Emissionswahrscheinlichkeiten \\
           \( B = \{ b_j_k | b_j_k = P(O_t = o_k | S_t = j) \} \)
     \item Vektor von Zustandsstartwahrscheinlichkeiten \\
           \( \pi = \{ \pi_i | \pi_i = P(S_1 = i) \} \) 
   \end{itemize}
   

\subsection{Datenvorbereitung}
Eine Aufnahme wird beschrieben durch ein zwei-dimensionales Array aus 32 Frames mit jeweils 64 Frequenzwerten.
Im Ruhezustand bildet sich ein Signalpeak um die ausgesendete Frequenz (18.500hz).
Ziel ist es die Daten zu normieren und die Datenmenge zu reduzieren, um das Trainingergebnis bzw. Performance zu verbessern.
Weiterhin wird versucht die relevanten Werte einer Geste aus der Aufnahme zu extrahieren.

Da sich Änderungen durch eine Bewegung sehr Nahe am gesendeten Signal liegen, werden die Daten im 
Frequenzbereich von 18.000hz bis 19000hz betrachtet, die Daten vermindern sich von 64 auf 13 Werte. 
Dazu wird jede Geste auf einem Intervall von 0 bis 1 normalisiert (Geteilt durch den jeweiligen Maximalwert) und 
auf zwei Nachkommstellen gerundet. 
Alle Werte unterhalb eines Schwellwerts (0.1) werden zudem abgeschnitten, um niedrig amplitudiges Rauschen zu vermindern. 
So wird im Idealfall nur das gesendete Signal und Frequenzänderungen durch eine Geste dargestellt.

Wichtig ist nun den Beginn und das Ende einer Geste zu finden. Hierzu werden pro Frame alle Werte addiert 
und das Maximum als Mittelpunkt der Geste genutzt. Von diesem Gestenhöhepunkt werden jeweils 6 Frames davor und danach mitgenutzt.

So wird aus einem 32 x 64 Array pro Geste ein 13x13 Array.


\subsection{Implementierung}
Wir haben uns für die scipy HMM implementierung entschieden. 
Genutzt wird ein \acl{HMM} mit \acl{GMM} entschieden.


\subsection{Evaluation und Fazit}
