\section{\acl{HMM}}
\label{mainsec:hmm}
\textit{Paul Pasler, Sebastian Rieder}

Das \acl{HMM} ist ein stochastisches Modell für sequentielle Daten und wird vor allem in der Spracherkennung und in der Bioinformatik eingesetzt.

In den folgenden beiden Abschnitten werden die Entstehung und Konzepte der \acl{MK} und des \acl{HMM} aufgezeigt.
Abschnitt \ref{sec:preproc} befasst sich mit der Aufbereitung der Daten für das Training und die Klassifizierung der Gesten.
Die Implementierung und Anwendung des \acl{HMM} werden im Abschnitt \ref{sec:impl} näher erläutert. Im letzten Abschnitt werden die Ergebnisse 
evaluiert und ein Fazit mit Ausblick gezogen.  
 
  %%%%%%%%%%%%%%%%%%
  %  MARKOV-KETTE  % 
  %%%%%%%%%%%%%%%%%%  
\subsection{\acl{MK}} \label{sec:chain}
Grundlage des \acl{HMM} war die vom russischen Mathematiker Andrej Andrejewitsch Markov 
(1856 - 1922, siehe \cite{markov1913}) entwickelte \acl{MK}. Zu Beginn des
20. Jahrhunderts beschäftigte er sich als erster mit einer statistischen Beschreibung von Zustands- und Symbolfolgen. 
Er führte eine statistische Analyse der Buchstabenfolge des Textes ``Eugen Onegin'' von Alexander 
Pushkin.

Eine \acl{MK} beschreibt einen zeit-diskreten Prozess \((X_t)_{t\in\mathbb{N}_0}\) mit  \(m\) abzählbaren Zuständen \(S\) \cite{stochMod}.
Weiterhin wird sie als stationär bezeichnet, wenn alle Wahrscheinlichkeiten unabhängig von der Zeit sind.
Da die Verteilung der Zufallsvariablen nur von den vergangenen Zuständen abhängt, gilt eine \acl{MK} als kausal \cite[48]{mmmFink}.
Wichtig für eine \acl{MK} ist die sog. Markov-Eigenschaft:
\[ P (X_{t+1} = s_{t+1} | X_0 = s_0, \ldots , X_{t-1} = s_{t-1}, X_{t} = s_{t}) \]
\[ = P ( X_{t+1} = s_{t+1} | X_{t} = s_{t} ) \] \\
Genügt eine \acl{MK} dieser Eigenschaft, wird sie als ``einfach'' oder \acl{MK} 1. Ordnung bezeichnet.
Anders ausgedrückt beschreibt die Markov-Eigenschaft die Gedächtnislosigkeit des Prozesses, da der Folgezustand nur vom direkten Vorgänger abhängt.

Als Übergangswahrscheinlichkeit bezeichnte man die bedingte Wahrscheinlichkeit \(P ( X_{t+1} = s_{t+1} | X_{t} = s_{t} ) \), sodass auf 
den aktuellen Zustand \( s_{t}\) der Nachfolgezustand \( s_{t+1}\) folgt. Diese Wahrscheinlichkeiten werden üblicherweise zu einer Übergangsmatrix zusammengefasst: 
\[ A = [a_{ij}] =
\begin {bmatrix} 
  a_{00}&\cdots&a_{0m} \\
  \vdots&\ddots&\vdots \\
  a_{m0}&\cdots&a_{mm}
 \end {bmatrix} \forall i, j \in S \]
Da es sich um Wahrscheinlichkeiten handelt, muss sich die Summe jeder Reihe zu Eins addieren. \\

Weiterhin benötigt der Prozess einen Vektor für den Anfangzustand \( t = 0 \):
\[ \Pi = [ \pi_i] = [ P (X_0 = i) ] , i \in S \]

So lässt sich eine Markov-Kette durch Zustandsraum \(S\), den Übergangsmatrix \( A \) und einen Anfangszustand \( \Pi \) definieren.
Veranschaulichen lässt sich eine Markov Kette als gerichtetes Zustandsdiagramm (Abb. \ref{fig:simple_mc}) mit den Zuständen \(S\) und 
mit den Übergangswahrscheinlichkeiten \(X_i\) an den Kanten
\begin{figure}[htbp] \centering
    \includegraphics[width=0.5\textwidth]{markov/simple_mc.png}
    \caption{Einfaches Zustandsdiagramm einer \acl{MK} (Quelle: \url{de.wikipedia.org/wiki/Markow-Kette})}
    \label{fig:simple_mc}
\end{figure}

Die Wahrscheinlichkeit für \( k \)-Schritte lässt sich so ausrechnen: 
\[ X_k = X_{k-1} A = X_0 A^k \] 


\textbf{Beispiel:} 
\textit{ \acl{MK} für das Wetter \footnote{Quelle: \url{en.wikipedia.org/wiki/Examples_of_Markov_chains}}} \\
Im folgenden Beispiel soll aufgrund des aktuellen Wetters auf das Wetter der folgenden Tage geschlossen werden.
Das Wetter kann entweder ``sunny'' oder ``rainy'' sein, zu Beginn (Tag 0, \( t = 0 \)) des Experiments ist es ``sunny''.
Die Wahrscheinlichkeit, dass auf ``sunny'' wieder ``sunny'' folgt, liegt bei 90\% (``rainy'' = 1 - ``sunny'' = 10\%). 
Nach ``rainy'' liegt die Wahrscheinlichkeit jeweils bei 50\%.  
\begin{figure}[htbp] \centering
    \includegraphics[width=0.5\textwidth]{markov/simple_mc_example.png}
    \caption{ Gerichteter Zustandsgraph der modellierten Wetter-\acl{MK} }
    \label{fig:simple_mc_example}
\end{figure}


\[ Zust\ddot{a}nde: S = [``sonnig'', ``regnerisch''] \]
\[ Anfangszustand:  \Pi = X_0 = [1 , 0] \]
\[\ddot{U}bergangsmatrix: A = \begin {bmatrix} 0.9&0.1\\0.5&0.5 \end {bmatrix}
\]

Nun kann die Wahrscheinlichkeit für das Wetter an Tag 1 berechnet werden über: \\
\[ X_1 = X_0 * A = [ 1, 0 ] \begin {bmatrix} 0.9&0.1\\0.5&0.5 \end {bmatrix} = [ 0.9, 0.1] \]

Für Tag 2:\\
\[ X_2 = X_1 A = X_0 A^2 = [ 1, 0 ] \begin {bmatrix} 0.9&0.1\\0.5&0.5 \end {bmatrix}^2 = [ 0.86, 0.14] \] 

Verallgemeinert für Tag k bedeutet das: 
\[ X_k = X_{k-1} A = X_0 A^k = [ 1, 0 ] \begin {bmatrix} 0.9&0.1\\0.5&0.5 \end {bmatrix}^k \] 


  %%%%%%%%%%%%%%%%%%
  %  HIDDEN-MARKOV  % 
  %%%%%%%%%%%%%%%%%%
\subsection{\acl{HMM} und \acl{GMM}}  \label{sec:hmm}
Der amerikanischen Mathematiker Leonard E. Baum (* 1931) und andere Autoren entwickelten auf Basis der \acl{MK} Ende der 
sechziger Jahre das \acl{HMM}. Erste \acl{HMM}-Applikationen wurden zur Spracherkennung und später auch in der Bioinformatik 
zur Analyse von Nukleotid- und Proteinsequenzen eingesetzt. 

Ein \acl{HMM} erweitert eine \acl{MK} um eine weiteren Zufallsprozess und ist
somit ein zweistufiger stochastischer Prozess \cite[67]{mmmFink}. Hierfür wird
jedem Zustand der \acl{MK} eine Ausgabe bzw. Emission zugeordnet dessen
Wahrscheinlichkeitsverteilung einzig vom aktuellen Zustand abhängig ist. Die
Emissionen sind die einzigen beobachtbaren Zustände des \acl{HMM}. Der Rest
ist sozusagen 'versteckt' woher sich auch der Name des Models ableitet. Eine
Folge von Emissionen wird auch Observationsfolge genannt.

\begin{figure}[htbp] \centering
    \includegraphics[width=0.4\textwidth]{markov/hmm_example.png}
    \caption{\acl{HMM} für das Beipiel des gefangen im Verlies}
    \label{fig:hmm_example}
\end{figure}

Abbildung \ref{fig:hmm_example} soll ein \acl{HMM} an dem Beispiel des
Gefangenen im Verlies darstellen\footnote{Quelle:
\url{http://de.wikipedia.org/wiki/Hidden_Markov_Model}}.Ein Gefangener im
Kerkerverlies möchte das aktuelle Wetter herausfinden. Er weiß, dass auf einen
sonnigen Tag zu 70 \% ein Regentag folgt und dass auf einen Regentag zu 50 \%
ein Sonnentag folgt. Weiß er zusätzlich, dass die Schuhe der Wärter bei Regen zu
90 \% dreckig, bei sonnigem Wetter aber nur zu 60 \% dreckig sind, so kann er
durch Beobachtung der Wärterschuhe Rückschlüsse über das Wetter ziehen (das
heißt, er kann die Wahrscheinlichkeit für Regenwetter gegenüber sonnigem Wetter
abschätzen). Sonne und Regen sind in diesem Fall die versteckten Zustände. Die
Emissionen bzw. die Observation die der Gefangene machen kann sind nur der
Verschmutzheitsgrad der Schuhe der Wärter.

Das \acl{HMM} wird definiert durch \cite[68]{mmmFink}:\\ 
\( \lambda = (S;V;A;B;\pi)\)
\begin{itemize}
     \item Endlich Menge von Zuständen \\
           \( S = \{ s | 1 <= s <= N \} \)
     \item Alphabeth der Emissionen \\
           \( V = \{ v | 1 <= v <= M \} \)
     \item Matrix der Zustandsübergangswahrscheinlichkeiten \\
           \( A = \{ a_{ij} | a_{ij} = P(S_t = j | S_{t-1} = i) \} \)
     \item Matrix der Emissionsverteilung \\
           \( B = \{ b_{jk} | b_{jk} = P(O_t = o_k | S_t = j) \} \) bzw. \( B =
           \{ b_{j}(x) | b_{j}(x) = p(x|S_t = j) \} \)
     \item Vektor von Zustandsstartwahrscheinlichkeiten \\
           \( \pi = \{ \pi_i | \pi_i = P(S_1 = i) \} \) 
\end{itemize}

Die Emissionsmodellierung ist hierbei vom Kontext der Problemstellung abhängig.
Wird das \acl{HMM} zum Beispiel bei der Analyse von biologischen Sequenzen,
sprich einem diskreten Symbolinventar, angewendet, wird ein diskretes
Emissionsmodel genutzt. Man spricht hierbei auch von einem diskreten \acl{HMM}.
Wenn dieses Model zur verarbeitung von Signalen verwendet werden soll erfordert
dies in der Vorverarbeitung der Daten einen Quantisierer der die
kontinuerlichen Merkmale in eine diskrete Observationsfolge überführt. 

Gängiger ist es hierfür kontinuierliche \acl{HMM}'s zu nutzen. Hierbei wird eine
Emissionsmodelierung auf Basis kontinuierlicher Dichtefunktionen genutzt die
kontinuierliche Observationen im \(\mathbb{R}^n\) verarbeitet.\\ 
\( B =\{ b_{j}(x) | b_{j}(x) = p(x|S_t = j) \} \)\\
Zur behandlung kontinuerlicher Verteilungen mit mehreren komplexen
Häufigkeitsgebieten werden approximatische Verfahren genutzt. Die verbreiteste
Technik besteht aus der Verwendung von Mischverteilungen auf der Basis von
Gauß-Dichten (\acl{GMM}). Man kann nämlich zeigen, dass sich jede allgemeine
kontinuierliche Verteilung \(p(x)\) durch eine Linearkombination von i.a. unendlich vielen
Basis-Normalverteilungen beliebig genau approximieren lässt\cite[69]{mmmFink}:
 
\begin{multline}
p(x) \hat{=} \sum_{k=1}^\infty c_{k} N(x|\mu_{k},K_{k})\\
\approx \sum_{k=1}^M c_{k} N(x|\mu_{k},K_{k})  
\end{multline}
Der Approximationsgfehler lässt sich hierbei über eine geeignete Anzahl von
\(M\) Basisverteilungen klein halten. Somit ergibt sich für die Beschreibung der
Emissionsverteilung eines Zustands des \acl{HMM} folgende Formel:
\begin{equation}
b_{j}(x) = \sum_{k=1}^M c_{jk}g_{jk}(x)
\end{equation}
Die Anzahl der Basisverteilungen eines \acl{GMM} kann hierbei für die einzelnen
Zustände des HMM variieren.\\

Das Konzept des \acl{HMM} kann laut \cite{rabiner} in drei Problemstellungen eingeteilt werden:
\begin{itemize}
  \item Evaluierungsproblem: Bestimme die Wahrscheinlichkeit für ein Model mit
  der dieses eine gegebene Observationsfolge erzeugt.
  \item Dekodierungsprobem: Finde interne Abläufe für eine gegebene Observationsfolge
  \item Trainingsproblem: Finde Modellparameter für gegebene Beispieldaten
\end{itemize}
\\
\textbf{Evaluierung} \\
In der Evaluierung soll die Wahrscheinlichkeit bestimmt werden mit der eine
betrachtete Observationsfolge in einer beliebiger Zustandsfolge von einem
gegebenen \acl{HMM} \(\lambda\) generiert wird. Diese Wahrscheinlichkeit wird
Produktionswahrscheinlichkeit genannt. Diese wird mit dem Forward-Algorithmus
berechnet. Der Algorithmus nutzt hierfür die geltende Markov Eigenschaft
aus das nur die Speicherung eines internen Zustandes erlaubt. Hierfür definiert
man als Vorwärtsvariable \(\alpha_{t}(i)\) die Wahrscheinlichkeit, bei
gegebenem Model \lampda den Anfang der betrachteten Observationsfolge \(O_{t}\)
zu erzeugen und zum Zeitpunkt \(t\) den Zustand i zu erreichen.
\begin{equation}
\alpha_{t}(i) = P(O_{1},O_{2},\ldots,O_{t},s_{t}=i|\lambda)
\end{equation}
Die Vorwährtsvariable lässt sich nun mit den folgenden Schritten rekursiv
berechnen um die Gesamtwahrscheinlichkeit des Models zu erhalten.
\begin{enumerate}
  \item Initialisierung\\
		$\alpha_{1}(i) := \pi_{i}b{i}(O_{1})$
  \item Rekursion\\
	für alle Zeitpunkte \(t, t=1 \ldots T-1\)\\
	\(\alpha_{t+1}(j) :=
	\sum\limits_{i}\{\alpha_{t}(i)\alpha_{ij}\}b_{j}(O_{t+1})\)
  \item Rekursionsabschluss\\
  	\(P(O|\lambda) = \sum\limits_{i=1}^N \alpha_{T}(i)\)
\end{enumerate}


\\
\textbf{Dekodierung} \\
Bei der Dekodierung soll die optimale, bzw. wahrscheinlichste Zustandsfolge
\(s^*\) aus der Menge der Zustände ermittelt werden die eine gegebene
Observationsfolge erzeugt. Zur Ermittlung der optimalen Zustandsfolge bedient
man sich des Viterbi-Algorithmus, einem induktiven Verfahren das dem Forward
Algorithmus sehr ähnlich ist. Zu Begin werden erneut die Wahrscheinlichkeiten
\(\delta_{t}(i)\) für partiell optimale Pfade definiert, die das Anfangssegment
der Observationsfolge bis \(O_{t}\) mit maximaler Wahrscheinlichkeit erzeugen
und in Zustand \(i\) enden.
\begin{equation}
\delta_{t}(i) =
\max\limits_{s_{1},s_{2}, \ldots
,s_{t}}P(O_{1},O_{2},\ldots,O_{t},s_{1},s_{2},\ldots,s_{t}=i|\lambda) 
\end{equation}
Der Algorithmus entspricht weitgehend dem Forward-Algorithmus jedoch werden
anstatt der Summe im Rekursionsabschluss, die Maximalen über die in den
Vorgängerzuständen vorliegenden Wahrscheinlichkeiten gebildet.
\begin{enumerate}
  \item Initialisierung\\
		\(\delta_{1}(i) := \pi_{i}b{i}(O_{1})\)\\
		\(\phi_{1}(i):=0\)
  \item Rekursion\\
	für alle Zeitpunkte \(t, t=1 \ldots T-1\)\\
	\(\delta_{t+1}(j) :=
	\max\limits_{i}\{\delta_{t}(i)\alpha_{ij}\}b_{j}(O_{t+1})\)\\
	\(\phi_{t+1}(j):= \operatorname{arg\,max}\limits_{i}\{\lambda_{t}(i)\alpha_{ij} \)
  \item Rekursionsabschluss\\
  	\(P^{*}(O|\lambda) = \(P(O,s^{*}|\lambda) = \max_{i}\lambda_{T}(i)
  	\alpha_{T}(i)\)
  \item Rückverfolgung des Pfades\\
	für alle Zeitpunkte \(t, t=1 \ldots T-1\)\\
	\(s_{t}^{*}=\phi_{t+1}(s_{t+1}^{*})\)
\end{enumerate}
Mit \(\phi_{t}(j)\) wird ein ``Rückwärtszeiger'' definiert der für jedes
entsprechende \(\delta_{t}(j)\) entlang der partiellen Pfade den jeweils
optimalen Vorgängerzustand speichert.\\
\textbf{Training} \\
Je nach Problemstellung müssen unterschiedliche Modelle eines HMM's gewählt
werden. Es ist bisher kein Verfahren bekannt das aufgrund einer Stichprobe ein
Optimales Modell generieren kann. Die Anzahl der Zustände, die Wahl der
Emissionsverteilungen sowie deren initialer Parameterwerte müssen nach
eigenen Erfahrungen gewählt werden. Wenn dies geschehen ist kann das Modell in
einem iterativen Prozess trainiert werden. Hierbei werden die Parameter
einer Wachstumstransformation unterworfen. Ziel ist es das die Modellparameter
so verändert werden das die Bewertung des veränderten Models besser als die des
Ausgangsmodels ist.\\

Zum trainieren eines \acl{HMM} existieren diverse Algorithmen. Sie unterscheiden
sich im wesentlichen durch die Verwendeten Qualitätsmaße zur Bewertung der
Modelierungsgüte. Beim Baum-Welch-Algorithmus \cite{rabiner} wird die
Produktionswahrscheinlichkeit \(P(O|\lambda)\) zur Bewertung genutzt. Beim
Viterbi-Algorithmus \cite{Viterbi} und dem eng verwandten Segmental-k-means
Algorithmus \cite{juang} nur die Wahrscheinlichkeit \(\(P(O,s^{*}|\lambda)\) der
jeweils optimalen Zustandsfolge betrachtet \cite{mmmfink}.

Um das Training und die Klassifizierung möglichst genau und performant
umzusetzen, ist es notwendig die aufgenommenen Daten aufzubereiten, dies ist Thema des
nächsten Abschnitts


  %%%%%%%%%%%%%%%%%%%
  %  PREPROCESSING  % 
  %%%%%%%%%%%%%%%%%%%
\subsection{Datenaufbereitung} \label{sec:preproc}
Ziel der Vorverarbeitung ist es die Daten zu normieren und die Datenmenge zu reduzieren, um das Trainingergebnis bzw. Performance zu verbessern.
Weiterhin werden relevante Werte bzw. Werte mit hohem Informationsgehalt einer Geste aus der Aufnahme vertärkt. \\


\textbf{Rohdaten} \\
Eine Aufnahme wird beschrieben durch ein zwei-dimensionales Array aus 32 Frames mit jeweils 64 Frequenzwerten.
Im Ruhezustand bildet sich ein Normalsignal mit einem Peak um die ausgesendete Frequenz (18.500hz, siehe Abb. \ref{fig:data_raw}).

\begin{figure}[htbp] \centering
    \includegraphics[width=0.5\textwidth]{markov/data_raw.png}
    \caption{Rohdaten direkt vom Recorder (\acl{RLO} Geste)}
    \label{fig:data_raw}
\end{figure}

\textbf{Verarbeitung}\\
Da die Änderungen durch eine Bewegung sehr Nahe am Normalignal liegen, werden nur die Daten im 
Frequenzbereich von ca. 18.300hz bis 18.700hz betrachtet. Dadurch vermindert sich die Datenmenge von 64 auf 16 Werte pro Frame. 
Danach wird jede Geste auf ein Intervall von 0 bis 1 normalisiert (Geteilt durch den jeweiligen Maximalwert der Geste) und 
auf zwei Nachkommstellen gerundet. 
Alle Werte unterhalb eines Schwellwerts (0.15) werden zudem abgeschnitten, um niedrig amplitudiges Rauschen zu vermindern. 
So wird im Idealfall nur das gesendete Signal und Frequenzänderungen durch eine Bewegung dargestellt.

Das Normalsignal mit einer hohen Amplitude (Normalisiert im Bereich zwischen 0.8 und 1.0) birgt einen geringen Informationsgehalt, 
eine Frequenzverschiebung durch eine Geste ist deutlich interessanter, jedoch schwächer in der Amplitude (Zwischen 0.15 und 0.5).
Darum wird werden niedrige Amplitudenwerte \( x \) verstärkt und hohe abgeschwächt. 
Folgende Funktion wird auf alle Werte angewendet  (Verlauf siehe Abb. \ref{fig:funktion}): \\
\[ f(x) = 2.8 \cdot ( x - 1.15 )^2 + 0.75 \]
\begin{figure}[htbp] \centering
    \includegraphics[width=0.5\textwidth]{markov/funktion.png}
    \caption{Kubische Parabel zur Verstärkung / Abschwächung der Amplitude}
    \label{fig:funktion}
\end{figure}

Nach der Vorverarbeitung sind die schwächeren Frequenzbereiche links und rechts neben dem Normalsignal deutlicher 
herausgearbeitet (Siehe Abb. \ref{fig:data_preproc}).  

\begin{figure}[htbp] \centering
    \includegraphics[width=0.5\textwidth]{markov/data_preproc.png}
    \caption{Daten nach der Vorverarbeitung (\acl{RLO} Geste)}
    \label{fig:data_preproc}
\end{figure}

\textbf{\acl{GMM}} \\
Aus den Vorverarbeiteten Daten werden Gauß’sche Mixtur Modelle berrechnet (Siehe Abb. \ref{fig:data_gmm}). 
Diese mitteln alle eingegebenen Trainingsdaten und erstellen pro Frame ein \acl{GMM} (Siehe Abschnitt: 
\ref{sec:impl}). So wird eine Geste mit n-Frames durch n-\acl{GMM}s repräsentiert.

\begin{figure}[htbp] \centering
    \includegraphics[width=0.5\textwidth]{markov/data_gmm.png}
    \caption{Sampledaten aus dem trainierten \acl{GMM} (\acl{RLO} Geste)}
    \label{fig:data_gmm}
\end{figure}


  %%%%%%%%%%%%%%%%%%%%%
  %  IMPLEMENTIERUNG  % 
  %%%%%%%%%%%%%%%%%%%%%
\subsection{Implementierung}  \label{sec:impl}
Wie im vorherigen Abschnitte erläutert, wird vor dem Training und der Klassifizierung eine Vorverabreitung der Daten durchgeführt \ref{fig:uml}.
Diese Vorverarbeitung wird in der Klasse \texttt{DataUtil} durchgeführt und nutzt die Klasse \texttt{GestureFileIO} der Hauptapplikation.

\begin{figure*}[htbp] \centering
    \includegraphics[width=1.0\textwidth]{markov/uml.png}
    \caption{Klassendiagram und Abhängigkeiten des \acl{HMM} Klassifikators}
    \label{fig:uml}
\end{figure*}


Die \texttt{HMM}-Klasse implementiert das Interface \texttt{IClassifier} und bildet die Schnittstelle zur Hauptapplikation. Sie nutzt \texttt{DataUtil}
 für alle Dateizugriffe und die \texttt{Plot}-Klasse, um diese Daten als Graphen darzustellen. 
Für das \acl{HMM} werden Objekte der Klassen \texttt{sklearn.hmm.GMMHMM} und \texttt{sklearn.mixture.GMM} aus \texttt{scikit-learn}-Bibliothek \url{scikit-learn.org} verwendet.


\begin{figure}[htbp] \centering
    \includegraphics[width=0.5\textwidth]{markov/gmm_data.png}
    \caption{Transformation für das Training der \acl{GMM}}
    \label{fig:gmm_data}
\end{figure}

\textbf{Das Training} \\
Herzstück der HMM-Package-Logik für das Training eines \acl{HMM} ist die \texttt{GestureApllication}-Klasse, welche eine Liste von \texttt{Gesture}-Beans vorhält. 
Diese Beans repräsentieren alle Daten die für 
 die Klassifizierung notwendig sind. Für das Training nutzt \texttt{GestureApplication} die \texttt{HMM\_Util}-Klasse.
\texttt{HMM\_Util} erstellt mit Hilfe der \texttt{GMM\_Util}-Klasse zuallererst eine List von trainierten \acl{GMM}s. Dazu werden die eingehenden Daten 
neu transformiert und nach Frames sortiert (siehe Abb. \ref{fig:data_gmm}). Somit repräsentiert ein \acl{GMM} einen Zeitpunkt während der Aufnahme 
(siehe Abb. \ref{fig:gmm_data}). Die trainierten \acl{GMM}s werden nun für das Training eines \acl{HMM} genutzt. Um beim Trainingsprozess eingreifen zu können
wurden die \texttt{sklearn}-Klassen erweitert, so entstehen die Klassen \texttt{GestureHMM} und \texttt{GestureGMM}. Dies ist notwendig, da die fertig trainierten
\acl{GMM}s während des \acl{HMM} Trainings noch einmal verändert werden - was allerdings unerwünscht ist. 


\textbf{Klassifizierung} \\
Wird die \texttt{classify}-Methode der \texttt{HMM}-Klasse getriggert, werden die eingehenden Frames in zwei versetzten Containern (Windows) gesammelt.
Ist eines dieser Windows voll (bei 32 Frames) wird die Klassifizierung in der \texttt{GestuerApplication} ausgelöst. Dort wird die Geste allen \acl{HMM}s übergeben und
bewertet (score) mit welcher Wahrscheinlichkeit es sich um diese Geste handelt.

  %%%%%%%%%%%%
  %  RESULT  % 
  %%%%%%%%%%%%
\subsection{Evaluation und Fazit}  \label{sec:result}
Das Hidden Markov Modell eignet sich grundsätzlich sehr gut für die gestellte Aufgabe. Da es mit sequenzielle Daten (Frames) umgehen 
kann und ursprünglich für die Spracherkennung entwickelt wurde. Ob nun aus einem Tonsignal (versteckte Zustände) ein Wort oder 
eine Geste (Emissionen) erkannt werden soll, ist vom Vorgehen ähnlich. Ein Vorteil ist zudem, dass die Ausführungsgeschwindigkeit
 der Geste, bei geeigneter Aufnahmelänge, die Klassifizierung nicht unbedingt beeinflusst, da dann länger im selben versteckten 
 Zustand verblieben wird.
Ein Nachteil dieser Methode ist, dass keine absoluten Klassifizierungen durchgeführt werden können. Es werden nur Wahrscheinlichkeiten für alle möglichen Klasse berechnet. 
So muss entschieden werden, ob die Wahrscheinlichkeit für eine Klasse hoch genug ist, sodass diese als Geste identifiziert werden kann.


